{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pe256\\anaconda3\\envs\\tracknet\\lib\\site-packages (from face_recognition) (1.24.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\pe256\\anaconda3\\envs\\tracknet\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\pe256\\anaconda3\\envs\\tracknet\\lib\\site-packages (from face_recognition) (8.0.4)\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Using cached face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: colorama in c:\\users\\pe256\\anaconda3\\envs\\tracknet\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Building wheels for collected packages: dlib, face-recognition-models\n",
      "  Building wheel for dlib (pyproject.toml): started\n",
      "  Building wheel for dlib (pyproject.toml): still running...\n",
      "  Building wheel for dlib (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for dlib: filename=dlib-19.24.2-cp310-cp310-win_amd64.whl size=2835525 sha256=4e27f9835748112fe195e2ea829c29d99df6b79520abb17fa3760c938c359f2e\n",
      "  Stored in directory: c:\\users\\pe256\\appdata\\local\\pip\\cache\\wheels\\9b\\e2\\80\\888fdc098db86b463ff0c83ae5e5ca151889e901bc1e9a3a11\n",
      "  Building wheel for face-recognition-models (setup.py): started\n",
      "  Building wheel for face-recognition-models (setup.py): finished with status 'done'\n",
      "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=5fbc0c10a7b7c8fc460d7fc24f3cedbca1dd9ba3fa25cbc1c51dabbb684d364e\n",
      "  Stored in directory: c:\\users\\pe256\\appdata\\local\\pip\\cache\\wheels\\7a\\eb\\cf\\e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
      "Successfully built dlib face-recognition-models\n",
      "Installing collected packages: face-recognition-models, dlib, face_recognition\n",
      "Successfully installed dlib-19.24.2 face-recognition-models-0.3.0 face_recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "A face is located at pixel location Top: 318, Left: 258, Bottom: 554, Right: 494\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "image = face_recognition.load_image_file(\"./datasets/Wonyoung/0.jpg\")\n",
    "\n",
    "# Find all the faces in the image using a pre-trained convolutional neural network.\n",
    "# This method is more accurate than the default HOG model, but it's slower\n",
    "# unless you have an nvidia GPU and dlib compiled with CUDA extensions. But if you do,\n",
    "# this will use GPU acceleration and perform well.\n",
    "# See also: find_faces_in_picture.py\n",
    "face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"cnn\")\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_locations)))\n",
    "\n",
    "for face_location in face_locations:\n",
    "\n",
    "    # Print the location of each face in this image\n",
    "    top, right, bottom, left = face_location\n",
    "    print(\"A face is located at pixel location Top: {}, Left: {}, Bottom: {}, Right: {}\".format(top, left, bottom, right))\n",
    "\n",
    "    # You can access the actual face itself like this:\n",
    "    face_image = image[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./img/unknown/W1.jpg,unknown_person\n",
      "./img/unknown/W4.jpg,Wonyoung\n",
      "./img/unknown/Y2.jpg,Yujin\n"
     ]
    }
   ],
   "source": [
    "!face_recognition --tolerance 0.4  ./img/known_people ./img/unknown/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./img/known_people\\Wonyoung.jpg,352,496,567,281\n",
      "./img/known_people\\Yujin.jpg,136,337,394,79\n"
     ]
    }
   ],
   "source": [
    "!face_detection  ./img/known_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41263791 0.47224394]\n",
      "0\n",
      "[0.46344029 0.55609059]\n",
      "0\n",
      "[0.55471818 0.45321861]\n",
      "1\n",
      "[0.56156101 0.55698021]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pe256\\AppData\\Local\\Temp\\ipykernel_19444\\3934015850.py:63: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  text_width, text_height = draw.textsize(name)\n",
      "C:\\Users\\pe256\\AppData\\Local\\Temp\\ipykernel_19444\\3934015850.py:63: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  text_width, text_height = draw.textsize(name)\n",
      "C:\\Users\\pe256\\AppData\\Local\\Temp\\ipykernel_19444\\3934015850.py:63: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  text_width, text_height = draw.textsize(name)\n",
      "C:\\Users\\pe256\\AppData\\Local\\Temp\\ipykernel_19444\\3934015850.py:63: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  text_width, text_height = draw.textsize(name)\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "# This is an example of running face recognition on a single image\n",
    "# and drawing a box around each person that was identified.\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "obama_image = face_recognition.load_image_file(\"./img/known_people/Wonyoung.jpg\")\n",
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "biden_image = face_recognition.load_image_file(\"./img/known_people/Yujin.jpg\")\n",
    "biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    obama_face_encoding,\n",
    "    biden_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Wonyoung\",\n",
    "    \"Yujin\"\n",
    "]\n",
    "\n",
    "# Load an image with an unknown face\n",
    "unknown_image = face_recognition.load_image_file(\"./img/unknown/all.jpg\")\n",
    "\n",
    "# Find all the faces and face encodings in the unknown image\n",
    "face_locations = face_recognition.face_locations(unknown_image)\n",
    "face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library\n",
    "# See http://pillow.readthedocs.io/ for more about PIL/Pillow\n",
    "pil_image = Image.fromarray(unknown_image)\n",
    "# Create a Pillow ImageDraw Draw instance to draw with\n",
    "draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "# Loop through each face found in the unknown image\n",
    "for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "    # See if the face is a match for the known face(s)\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # If a match was found in known_face_encodings, just use the first one.\n",
    "    # if True in matches:\n",
    "    #     first_match_index = matches.index(True)\n",
    "    #     name = known_face_names[first_match_index]\n",
    "\n",
    "    # Or instead, use the known face with the smallest distance to the new face\n",
    "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    print(face_distances)\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    print(best_match_index)\n",
    "    if matches[best_match_index]:\n",
    "        name = known_face_names[best_match_index]\n",
    "\n",
    "    # Draw a box around the face using the Pillow module\n",
    "    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "    # Draw a label with a name below the face\n",
    "    text_width, text_height = draw.textsize(name)\n",
    "    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "\n",
    "# Remove the drawing library from memory as per the Pillow docs\n",
    "del draw\n",
    "\n",
    "# Display the resulting image\n",
    "pil_image.show()\n",
    "\n",
    "# You can also save a copy of the new image to disk if you want by uncommenting this line\n",
    "# pil_image.save(\"image_with_boxes.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
